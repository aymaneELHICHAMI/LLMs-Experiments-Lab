{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanup - Tweet Dataset (Darija - Moroccan Dialect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this first stage we aim at clean a tweet dataset from Hugging Face (`shmuhammad/AfriSenti-twitter-sentiment`), \n",
    "focusing on the Moroccan Darija subset. The goal is to preprocess the text data by removing emojis, usernames,\n",
    "and applying custom list of Darija stop words. The cleaned data will then be ready for n-gram analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all : install dependencies \n",
    "%pip install datasets emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and filter to focus in Moroccan Darija\n",
    "from datasets import load_dataset\n",
    "moroccan_tweets = load_dataset(\"shmuhammad/AfriSenti-twitter-sentiment\", 'arq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset format is:  {'train': ['tweet', 'label'], 'validation': ['tweet', 'label'], 'test': ['tweet', 'label']}\n",
      "The number of elements of train subset:  1651\n",
      "The number of elements of test subset:  958\n",
      "The number of elements of validation subset:  414\n",
      "The labels of the dataset are:  ['positive', 'neutral', 'negative']\n",
      "\n",
      "{'tweet': '@user على حسب موقعك يبدو أنك صاحب نظرة ثاقبة .يخي تبهليل . @user', 'label': 2}\n",
      "{'tweet': '@user تبهليل هاذا', 'label': 2}\n",
      "{'tweet': '@user هاذي تبهليل ماشي فهامة', 'label': 2}\n"
     ]
    }
   ],
   "source": [
    "print('The dataset format is: ', moroccan_tweets.column_names)\n",
    "print('The number of elements of train subset: ', len(moroccan_tweets['train']))\n",
    "print('The number of elements of test subset: ', len(moroccan_tweets['test']))\n",
    "print('The number of elements of validation subset: ', len(moroccan_tweets['validation']))\n",
    "print('The labels of the dataset are: ', moroccan_tweets['train'].features['label'].names)\n",
    "print('')\n",
    "for i in range(3):\n",
    "    print(moroccan_tweets['train'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Processing (Remove emojis, usernames, URLs, Links, special charcters, punctuation, Remove Latin words, conversion to lower case if applicable)\n",
    "import re\n",
    "import emoji\n",
    "def clean_text(row):\n",
    "    row['tweet'] = re.sub(r'@\\w+', '', row['tweet'])  # Remove usernames\n",
    "    row['tweet'] = re.sub(r'http\\S+|www\\S+', '', row['tweet'])  # Remove URLs\n",
    "    row['tweet'] = re.sub(r'\\W+', ' ', row['tweet'])  # Remove special characters and punctuation\n",
    "    row['tweet'] = re.sub(r'\\s+', ' ', row['tweet'])  # Normalize whitespace\n",
    "    row['tweet'] = re.sub(r'[A-Za-z]+', ' ', row['tweet'])  # Remove Latin words\n",
    "    row['tweet'] = emoji.replace_emoji(row['tweet'], replace='') # Remove emojis\n",
    "    row['tweet'] = row['tweet'].strip()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few examples from the train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1651/1651 [00:00<00:00, 7439.61 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tweet': 'على حسب موقعك يبدو أنك صاحب نظرة ثاقبة يخي تبهليل', 'label': 2}\n",
      "{'tweet': 'تبهليل هاذا', 'label': 2}\n",
      "{'tweet': 'هاذي تبهليل ماشي فهامة', 'label': 2}\n",
      "\n",
      "Few examples from the test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 958/958 [00:00<00:00, 9592.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tweet': 'لاباس الحمدالله يارب العالمين اجمعين  سقسي عليك الخير يارب إسحاق', 'label': 0}\n",
      "{'tweet': 'لمجرب ولا تسقسي الطبيب', 'label': 1}\n",
      "{'tweet': 'عليه الميت لوكان يصيب يعيش و ميخليكش و الحي يتكبر و يلعبها من غير الفراق هذاك حاجة متستاهل تبكي عليها كي تروح من لخ', 'label': 1}\n",
      "\n",
      "Few examples from the validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 414/414 [00:00<00:00, 8775.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tweet': 'ههههههههههههه شوفي تاريخ بلدك بعدها تحدثي عن تاريخ اسيادك حبيبتي انت غ', 'label': 2}\n",
      "{'tweet': 'يسموه تبهليل بصح ضحكتني كي ناضت و راحت تجري ل طومبيل ع اساس تم تب', 'label': 2}\n",
      "{'tweet': 'في علم النفس ساعة ساعة ترفه على روحك بشوية تبهليل', 'label': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying Text Processing Function\n",
    "\n",
    "print('Few examples from the train set')\n",
    "moroccan_tweets['train'] = moroccan_tweets['train'].map(clean_text)\n",
    "for i in range(3):\n",
    "    print(moroccan_tweets['train'][i])\n",
    "print('')\n",
    "\n",
    "print('Few examples from the test set')\n",
    "moroccan_tweets['test'] = moroccan_tweets['test'].map(clean_text)\n",
    "for i in range(3):\n",
    "    print(moroccan_tweets['test'][i])\n",
    "print('')\n",
    "\n",
    "print('Few examples from the validation set')\n",
    "moroccan_tweets['validation'] = moroccan_tweets['validation'].map(clean_text)\n",
    "for i in range(3):\n",
    "    print(moroccan_tweets['validation'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Words Removal\n",
    "# We need a list of darija stop words to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  label\n",
      "0  على حسب موقعك يبدو أنك صاحب نظرة ثاقبة يخي تبهليل      2\n",
      "1                                        تبهليل هاذا      2\n",
      "2                             هاذي تبهليل ماشي فهامة      2\n",
      "3  تخاف نجاوب يا ناصر ببلوك لانو طريقة السؤال فيه...      2\n",
      "4         مرنكة أقسم بالله تبهليل ما بعد منتصف الليل      2\n",
      "tweet    0\n",
      "label    0\n",
      "dtype: int64\n",
      "tweet    0\n",
      "label    0\n",
      "dtype: int64\n",
      "tweet    0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ههههههههههههه شوفي تاريخ بلدك بعدها تحدثي عن ت...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>يسموه تبهليل بصح ضحكتني كي ناضت و راحت تجري ل ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>في علم النفس ساعة ساعة ترفه على روحك بشوية تبهليل</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>باين من قشهم مش عندنا بركا من تبهليل راك كبير ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ويفعلوها وجوه البخس مرة اخرى ويقلك وعلاه يكرهو...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>أنا مسامحك ولكن منقدرش ناكل داكشي حلو عليا بزاف</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>مات في روحك بزاف</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>السلام عليكم وقع لي مشكل كبييير بزاف انا وختي ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>القنطة كي تكون بزاف تضحك</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>عجبتيني بزاف</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  label\n",
       "0    ههههههههههههه شوفي تاريخ بلدك بعدها تحدثي عن ت...      2\n",
       "1    يسموه تبهليل بصح ضحكتني كي ناضت و راحت تجري ل ...      2\n",
       "2    في علم النفس ساعة ساعة ترفه على روحك بشوية تبهليل      0\n",
       "3    باين من قشهم مش عندنا بركا من تبهليل راك كبير ...      2\n",
       "4    ويفعلوها وجوه البخس مرة اخرى ويقلك وعلاه يكرهو...      2\n",
       "..                                                 ...    ...\n",
       "409    أنا مسامحك ولكن منقدرش ناكل داكشي حلو عليا بزاف      1\n",
       "410                                   مات في روحك بزاف      2\n",
       "411  السلام عليكم وقع لي مشكل كبييير بزاف انا وختي ...      2\n",
       "412                           القنطة كي تكون بزاف تضحك      2\n",
       "413                                       عجبتيني بزاف      0\n",
       "\n",
       "[413 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Validation (Check for empty/null values, remove duplicate entries, text length)\n",
    "import pandas as pd\n",
    "\n",
    "# Conversion to pandas Dataframes\n",
    "moroccan_tweets_train_df = pd.DataFrame(moroccan_tweets['train'])\n",
    "moroccan_tweets_test_df = pd.DataFrame(moroccan_tweets['test'])\n",
    "moroccan_tweets_validation_df = pd.DataFrame(moroccan_tweets['validation'])\n",
    "print(moroccan_tweets_train_df.head())\n",
    "\n",
    "# Check for empty values\n",
    "print(moroccan_tweets_train_df.isnull().sum())\n",
    "print(moroccan_tweets_test_df.isnull().sum())\n",
    "print(moroccan_tweets_validation_df.isnull().sum())\n",
    "\n",
    "# remove duplicates\n",
    "moroccan_tweets_train_df.drop_duplicates()\n",
    "moroccan_tweets_test_df.drop_duplicates()\n",
    "moroccan_tweets_validation_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 125\n",
      "زعما\n",
      "ايه حتا و أنا قلت هاذي تبقى مسألة شخصية كلها و كيفاش و وقتاش و الطريقة لي تساعدك الزواج بصفة عامة مسألة نسبية و كلها و مكتوبه\n"
     ]
    }
   ],
   "source": [
    "# Longest and shortest tweets on train subset\n",
    "shortest_tweet = moroccan_tweets_train_df.loc[moroccan_tweets_train_df['tweet'].str.split().str.len().idxmin()]\n",
    "longest_tweet = moroccan_tweets_train_df.loc[moroccan_tweets_train_df['tweet'].str.split().str.len().idxmax()]\n",
    "min_len, max_len = len(shortest_tweet['tweet']), len(longest_tweet['tweet'])\n",
    "print(min_len, max_len)\n",
    "print(shortest_tweet['tweet'])\n",
    "print(longest_tweet['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: N-grams Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-gram Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization and Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
